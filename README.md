# ğŸ¤Ÿ Real-Time Sign Language Detection and Translation System.  

> A real-time **American Sign Language (ASL)** recognition web app that captures hand gestures using a webcam and predicts ASL letters instantly in your browser.  

---

## ğŸŒŸ Overview  

This project combines **computer vision** and **deep learning** to translate ASL hand gestures into text in real-time.  

- ğŸ§  Built with **TensorFlow/Keras** for deep learning  
- âœ‹ Uses **MediaPipe** for hand landmark detection  
- ğŸŒ Powered by **Flask** for the web interface  
- âš¡ Runs directly in your browser â€” no extra software required  


---

## ğŸ§  Features  

âœ¨ **Smart Sign Recognition** â€” Detects ASL letters and words in real time using your webcam.  
ğŸ¤– **Deep Learning Powered** â€” Trained on hand landmark distances with a TensorFlow model.  
âœ‹ **MediaPipe Integration** â€” Tracks 21 key hand landmarks for accurate recognition.  
ğŸ“ **Dual Modes** â€” Switch between **single sign** and **sentence** prediction modes.  
ğŸ—‘ï¸ **Interactive Controls** â€” Easily **add spaces**, **delete letters**, or **clear text** with on-screen buttons.  
ğŸ’¾ **Persistent Model & Labels** â€” Saves trained model (`model.keras`) and label mapping for seamless reuse.  

---

## ğŸ—‚ï¸ Project Structure  

```plaintext
asl-sign-detection/
â”‚
â”œâ”€â”€ app.py               # Flask web application
â”œâ”€â”€ train_model.py       # Model training script
â”œâ”€â”€ model.keras          # Saved trained TensorFlow model
â”œâ”€â”€ label_mapping.npy    # Encoded label dictionary
â”œâ”€â”€ sign_data.csv        # Dataset of hand landmarks
â”‚
â”œâ”€â”€ templates/           # HTML templates
â”‚   â””â”€â”€ index.html       # Front-end UI
â”‚
â”œâ”€â”€ static/              # Static files (CSS, JS, images)
â”‚   â””â”€â”€ signs.png        # Example image asset
â”‚
â””â”€â”€ README.md            # Project documentation
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone this repository
```bash
git clone https://github.com/<your-username>/asl-sign-detection.git
cd asl-sign-detection
```

2ï¸âƒ£ Create a virtual environment (optional but recommended)
```bash
python -m venv venv
venv\Scripts\activate       # On Windows
# or
source venv/bin/activate    # On Mac/Linux
```

3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

4ï¸âƒ£ Run the Flask app
```bash
python app.py
```

Then open your browser and visit:
ğŸ‘‰ http://127.0.0.1:5000

## ğŸ§© Training the Model
1. If you want to train your own model:

2. Prepare your dataset sign_data.csv (with columns like Distance_0 ... Distance_209 and a label column Sign).

### Run:

```bash
python train_model.py
```

3. The script will:

- Train a neural network

- Display accuracy, confusion matrix, and classification report

### Save:

- model.keras

- label_mapping.npy

## ğŸ–¥ï¸ How It Works
1. MediaPipe detects 21 hand landmarks from the webcam feed.

2. Feature extraction calculates pairwise distances between landmarks (210 features).

3. Neural network model (trained with TensorFlow) predicts which ASL letter the hand sign represents.

4. Flask updates the live camera feed and displays:

5. Current sign

6. Confidence level

7. Sentence being formed

## ğŸ® App Controls
Action	Description

â–¶ï¸ Start Camera	Begins webcam feed

ğŸª„ Mode: Sign	Detects one sign at a time

âœï¸ Mode: Sentence	Builds continuous text from signs

â£ Add Space	Adds a space to the sentence

âŒ« Delete Last	Removes last character

ğŸ§¹ Clear Sentence	Clears full text

ğŸ”» Shutdown	Stops camera and app

## ğŸ§¾ Dependencies
Listed in requirements.txt:

- Flask
- numpy
- opencv-python
- mediapipe
- tensorflow
- scikit-learn
- matplotlib
- seaborn

## ğŸ§± Tech Stack  

| Category          | Technologies Used                                    |
|--------------------|-----------------------------------------------------|
| ğŸ¨ **Frontend**     | HTML5, CSS3, JavaScript *(Flask Templates)*        |
| ğŸ§© **Backend**      | Python (Flask)                                     |
| ğŸ§  **ML / AI**       | TensorFlow, Keras                                 |
| âœ‹ **Computer Vision** | OpenCV, MediaPipe                               |
| ğŸ“Š **Visualization**  | Matplotlib, Seaborn                              |


## ğŸš€ Future Improvements
âœ‹ Add support for dynamic signs (words/sentences via video)

ğŸ”¤ Expand dataset with more signs

ğŸŒ Host on Render / Hugging Face Spaces

ğŸ“± Create a mobile-friendly interface


## ğŸ“„ License
This project is licensed under the MIT License â€” youâ€™re free to use, modify, and distribute it with attribution.

## â¤ï¸ Acknowledgements
- Google MediaPipe

- TensorFlow

- OpenCV

---

â­ If you found this project helpful, give it a star on GitHub! â­

